{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SRGAN-test1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jason-zl190/deeplearning/blob/master/SRGAN_test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_xnMOsbqHz61"
      },
      "source": [
        "# SRGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "## Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YfIk2es3hJEd",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# try:\n",
        "#   # %tensorflow_version only exists in Colab.\n",
        "#   %tensorflow_version 2.x\n",
        "# except Exception:\n",
        "#   pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v13i0Hf_WUTc",
        "colab_type": "text"
      },
      "source": [
        "# utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbWmCF63WUTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bicubic Downsample For Oxford Dogs\n",
        "def bicubic_kernel(x, a=-0.5):\n",
        "  \"\"\"https://clouard.users.greyc.fr/Pantheon/experiments/rescaling/index-en.html#bicubic\"\"\"\n",
        "  if abs(x) <= 1:\n",
        "    return (a + 2)*abs(x)**3 - (a + 3)*abs(x)**2 + 1\n",
        "  elif 1 < abs(x) and abs(x) < 2:\n",
        "    return a*abs(x)**3 - 5*a*abs(x)**2 + 8*a*abs(x) - 4*a \n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def build_filter(factor):\n",
        "  size = factor*4\n",
        "  k = np.zeros((size))\n",
        "  for i in range(size):\n",
        "    x = (1/factor)*(i- np.floor(size/2) +0.5)\n",
        "    k[i] = bicubic_kernel(x)\n",
        "  k = k / np.sum(k)\n",
        "  # make 2d\n",
        "  k = np.outer(k, k.T)\n",
        "  k = tf.constant(k, dtype=tf.float32, shape=(size, size, 1, 1))\n",
        "  return tf.concat([k, k, k], axis=2)\n",
        "\n",
        "def apply_bicubic_downsample(x, filter, factor):\n",
        "  \"\"\"Downsample x by a factor of factor, using the filter built by build_filter()\n",
        "  x: a rank 4 tensor with format NHWC\n",
        "  filter: from build_filter(factor)\n",
        "  factor: downsampling factor (ex: factor=2 means the output size is (h/2, w/2))\n",
        "  \"\"\"\n",
        "  # using padding calculations from https://www.tensorflow.org/api_guides/python/nn#Convolution\n",
        "  filter_height = factor*4\n",
        "  filter_width = factor*4\n",
        "  strides = factor\n",
        "  pad_along_height = max(filter_height - strides, 0)\n",
        "  pad_along_width = max(filter_width - strides, 0)\n",
        "  # compute actual padding values for each side\n",
        "  pad_top = pad_along_height // 2\n",
        "  pad_bottom = pad_along_height - pad_top\n",
        "  pad_left = pad_along_width // 2\n",
        "  pad_right = pad_along_width - pad_left\n",
        "  # apply mirror padding\n",
        "  x = tf.pad(x, [[0,0], [pad_top,pad_bottom], [pad_left,pad_right], [0,0]], mode='REFLECT')\n",
        "  # downsampling performed by strided conv\n",
        "  x = tf.nn.depthwise_conv2d(x, filter=filter, strides=[1,strides,strides,1], padding='VALID')\n",
        "  return x\n",
        "\n",
        "# normalize\n",
        "# def normalize(image):\n",
        "#     image = tf.cast(image, dtype=tf.float32)\n",
        "#     return (image-tf.math.reduce_min(image))/(tf.math.reduce_max(image)-tf.math.reduce_min(image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylZbRlVjWUTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = np.ones([224, 224, 3], dtype=np.float32)\n",
        "k = build_filter(factor=4)\n",
        "down_result = apply_bicubic_downsample(tf.expand_dims(inp, 0), filter=k, factor=4)\n",
        "#down_result = down_model(tf.expand_dims(inp, 0))\n",
        "print(tf.expand_dims(inp, 0).shape)\n",
        "print (down_result.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "## Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXlUfd9eWUTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pickup_image(data_dict):\n",
        "  real_image = data_dict['image']\n",
        "  real_image = tf.cast(real_image, tf.float32)\n",
        "  return real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhUapllAWUTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_lr_sr_pair(real_image, downsampling_factor=4):\n",
        "  k = build_filter(factor=downsampling_factor)\n",
        "  lr = apply_bicubic_downsample(real_image, filter=k, factor=4)\n",
        "  sr = real_image\n",
        "  return lr, sr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWa7FSOYWUTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image(data):\n",
        "    real_image = pickup_image(data)\n",
        "    real_image = tf.expand_dims(real_image, 0)\n",
        "    lr, sr = make_lr_sr_pair(real_image)\n",
        "    lr = lr[0]\n",
        "    sr = sr[0]\n",
        "    return lr, sr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aO9ZAGH5K3SY",
        "colab": {}
      },
      "source": [
        "ds = tfds.load('oxford_iiit_pet')\n",
        "train_dataset = ds['train'].map(load_image)\n",
        "test_dataset = ds['test'].map(load_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiVr-rVWWUTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for inp, re in train_dataset: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4OLHMpsQ5aOv",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=[20,20])\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(inp/255.0)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(re/255.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5EV_M7DWUTq",
        "colab_type": "text"
      },
      "source": [
        "# data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rwwYQpu9FzDu",
        "colab": {}
      },
      "source": [
        "def resize(input_image, real_image, height, width):\n",
        "  input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  real_image = tf.image.resize(real_image, [height, width],\n",
        "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "  return input_image, real_image\n",
        "\n",
        "\n",
        "def random_crop(input_image, real_image):\n",
        "  stacked_image = tf.stack([input_image, real_image], axis=0)\n",
        "  cropped_image = tf.image.random_crop(\n",
        "      stacked_image, size=[2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "\n",
        "  return cropped_image[0], cropped_image[1]\n",
        "\n",
        "\n",
        "# normalizing the images to [-1, 1]\n",
        "def normalize(input_image, real_image):\n",
        "  input_image = (input_image / 127.5) - 1\n",
        "  real_image = (real_image / 127.5) - 1\n",
        "\n",
        "  return input_image, real_image\n",
        "\n",
        "\n",
        "@tf.function()\n",
        "def random_jitter(input_image, real_image):\n",
        "  # resizing to 286 x 286 x 3\n",
        "  input_image, real_image = resize(input_image, real_image, 286, 286)\n",
        "\n",
        "  # randomly cropping to 256 x 256 x 3\n",
        "  input_image, real_image = random_crop(input_image, real_image)\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    # random mirroring\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n0OGdi6D92kM",
        "colab": {}
      },
      "source": [
        "# As you can see in the images below\n",
        "# that they are going through random jittering\n",
        "# Random jittering as described in the paper is to\n",
        "# 1. Resize an image to bigger height and width\n",
        "# 2. Randomnly crop to the original size\n",
        "# 3. Randomnly flip the image horizontally\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "rj_inp, rj_re = random_jitter(inp, re)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(rj_inp/255.0)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(rj_re/255.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PIGN6ouoQxt3"
      },
      "source": [
        "## Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2CbTEt448b4R",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 400\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "D_WIDTH = 56\n",
        "D_HEIGHT = 56"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyaP4hLJ8b4W",
        "colab": {}
      },
      "source": [
        "def load_image_train(data_dict):\n",
        "  input_image, real_image = load_image(data_dict)\n",
        "  \n",
        "  input_image, real_image = random_jitter(input_image, real_image)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  \n",
        "  input_image = tf.image.resize(input_image, [D_HEIGHT, D_WIDTH], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return input_image, real_image\n",
        "\n",
        "def load_image_test(data_dict):\n",
        "  input_image, real_image = load_image(data_dict)\n",
        "  input_image, real_image = resize(input_image, real_image,\n",
        "                                   IMG_HEIGHT, IMG_WIDTH)\n",
        "  input_image, real_image = normalize(input_image, real_image)\n",
        "  input_image = tf.image.resize(input_image, [D_HEIGHT, D_WIDTH], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "\n",
        "\n",
        "  return input_image, real_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SQHmYSmk8b4b",
        "colab": {}
      },
      "source": [
        "ds = tfds.load('oxford_iiit_pet')\n",
        "train_dataset = ds['train']\n",
        "train_dataset = train_dataset.map(load_image_train,\n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MS9J0yA58b4g",
        "colab": {}
      },
      "source": [
        "test_dataset = ds['test']\n",
        "test_dataset = test_dataset.map(load_image_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk9hMNyIWUT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for inp, re in train_dataset: break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdCUIVjBWUT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=[20,20])\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(inp[0])\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(re[0])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Build the Generator\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVYDd95vWUT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(tf.keras.Model):\n",
        "  \"\"\"SRResnet\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__(name='Generator')\n",
        "    \n",
        "    # k9n64s1\n",
        "    self.conv1 = tf.keras.layers.Conv2D(64, 9, 1, padding='same')\n",
        "    self.prelu1 = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    \n",
        "    # B residual blocks\n",
        "    # conv2_1, k3n64s1\n",
        "    self.conv21a = tf.keras.layers.Conv2D(64, 3, 1, padding='same')\n",
        "    self.bn21a = tf.keras.layers.BatchNormalization()\n",
        "    self.prelu21a = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    self.conv21b = tf.keras.layers.Conv2D(64, 3, padding='same')\n",
        "    self.bn21b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.x21_append = tf.keras.layers.Conv2D(64, 1, 1, padding='same', use_bias=False)\n",
        "    self.bn_x21 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "     \n",
        "    # conv2_2, k3n64s1\n",
        "    self.conv22a = tf.keras.layers.Conv2D(64, 3, 1, padding='same')\n",
        "    self.bn22a = tf.keras.layers.BatchNormalization()\n",
        "    self.prelu22a = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    self.conv22b = tf.keras.layers.Conv2D(64, 3, padding='same')\n",
        "    self.bn22b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.x22_append = tf.keras.layers.Conv2D(64, 1, 1, padding='same', use_bias=False)\n",
        "    self.bn_x22 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    # conv2_3, k3n64s1\n",
        "    self.conv23a = tf.keras.layers.Conv2D(64, 3, 1, padding='same')\n",
        "    self.bn23a = tf.keras.layers.BatchNormalization()\n",
        "    self.prelu23a = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    self.conv23b = tf.keras.layers.Conv2D(64, 3, padding='same')\n",
        "    self.bn23b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.x23_append = tf.keras.layers.Conv2D(64, 1, 1, padding='same', use_bias=False)\n",
        "    self.bn_x23 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "\n",
        "    # conv2_4, k3n64s1\n",
        "    self.conv24a = tf.keras.layers.Conv2D(64, 3, 1, padding='same')\n",
        "    self.bn24a = tf.keras.layers.BatchNormalization()\n",
        "    self.prelu24a = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    self.conv24b = tf.keras.layers.Conv2D(64, 3, padding='same')\n",
        "    self.bn24b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.x24_append = tf.keras.layers.Conv2D(64, 1, 1, padding='same', use_bias=False)\n",
        "    self.bn_x24 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "\n",
        "    # conv2_5, k3n64s1 -- end of B residual block\n",
        "    self.conv25a = tf.keras.layers.Conv2D(64, 3, 1, padding='same')\n",
        "    self.bn25a = tf.keras.layers.BatchNormalization()\n",
        "    self.prelu25a = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    self.conv25b = tf.keras.layers.Conv2D(64, 3, padding='same')\n",
        "    self.bn25b = tf.keras.layers.BatchNormalization()\n",
        "    \n",
        "    self.x25_append = tf.keras.layers.Conv2D(64, 1, 1, padding='same', use_bias=False)\n",
        "    self.bn_x25 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "\n",
        "    # conv3, k3n64s1\n",
        "    self.conv3 = tf.keras.layers.Conv2D(64, 3, 1, padding='same')\n",
        "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "    self.x3_append = tf.keras.layers.Conv2D(64, 1, 1, padding='same', use_bias=False)\n",
        "    self.bn_x3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    # conv4_1, k3n256s1\n",
        "    self.conv41 = tf.keras.layers.Conv2D(256, 3, 1, padding='same')\n",
        "    self.prelu41 = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "    # conv4_2\n",
        "    self.conv42 = tf.keras.layers.Conv2D(256, 3, 1, padding='same')\n",
        "    self.prelu42 = tf.keras.layers.PReLU(alpha_initializer='zeros')\n",
        "\n",
        "    # conv5, k9n3s1\n",
        "    self.conv5 = tf.keras.layers.Conv2D(3, 9, 1, padding='same')\n",
        "    \n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    input_tensor = self.conv1(input_tensor)\n",
        "    input_tensor = self.prelu1(input_tensor)\n",
        "    \n",
        "     # B residual blocks\n",
        "    # conv2_1, k3n64s1\n",
        "    x = self.conv21a(input_tensor)\n",
        "    x = self.bn21a(x)\n",
        "    x = self.prelu21a(x)                          \n",
        "    x = self.conv21b(x)                         \n",
        "    x = self.bn21b(x)                 \n",
        "    x_append = self.x21_append(input_tensor)\n",
        "    x += x_append                   \n",
        "    x21 = self.bn_x21(x)                 \n",
        "\n",
        "     \n",
        "    # conv2_2, k3n64s1\n",
        "    x = self.conv22a(x21)          \n",
        "    x = self.bn22a(x)               \n",
        "    x = self.prelu22a(x)                 \n",
        "    x = self.conv22b(x)          \n",
        "    x = self.bn22b(x)                  \n",
        "    x_append = self.x22_append(x21)\n",
        "    x += x_append                   \n",
        "    x22 = self.bn_x22(x)                 \n",
        "\n",
        "    # conv2_3, k3n64s1\n",
        "    x = self.conv23a(x22)         \n",
        "    x = self.bn23a(x)                \n",
        "    x = self.prelu23a(x)              \n",
        "    x = self.conv23b(x)          \n",
        "    x = self.bn23b(x)                \n",
        "    \n",
        "    x_append = self.x23_append(x22)\n",
        "    x += x_append           \n",
        "    x23 = self.bn_x23(x)                \n",
        "\n",
        "\n",
        "    # conv2_4, k3n64s1\n",
        "    x = self.conv24a(x23)           \n",
        "    x = self.bn24a(x)                \n",
        "    x = self.prelu24a(x)             \n",
        "    x = self.conv24b(x)          \n",
        "    x = self.bn24b(x)                \n",
        "    \n",
        "    x_append = self.x24_append(x23)\n",
        "    x += x_append              \n",
        "    x24 = self.bn_x24(x)                \n",
        "\n",
        "\n",
        "    # conv2_5, k3n64s1 -- end of B residual block\n",
        "    x = self.conv25a(x24)           \n",
        "    x = self.bn25a(x)                \n",
        "    x = self.prelu25a(x)             \n",
        "    x = self.conv25b(x)          \n",
        "    x = self.bn25b(x)                \n",
        "    \n",
        "    x_append = self.x25_append(x24)\n",
        "    x += x_append              \n",
        "    x25 = self.bn_x25(x)                \n",
        "\n",
        "\n",
        "    # conv3, k3n64s1\n",
        "    x = self.conv3(x25)        \n",
        "    x = self.bn3(x)                \n",
        "    x_append = self.x3_append(input_tensor)\n",
        "    x += x_append\n",
        "    x = self.bn_x3(x)      \n",
        "\n",
        "\n",
        "    # conv4_1, k3n256s1\n",
        "    x = self.conv41(x) \n",
        "    x = tf.nn.depth_to_space(x, block_size=2)               \n",
        "    x = self.prelu41(x)             \n",
        "    # conv4_2\n",
        "    x = self.conv42(x)\n",
        "    x = tf.nn.depth_to_space(x, block_size=2)               \n",
        "    x = self.prelu42(x)             \n",
        "\n",
        "    # conv5, k9n3s1\n",
        "    x = self.conv5(x)         \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUqaqglEWUT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator()\n",
        "\n",
        "\n",
        "gen_output = generator(inp, training=False)\n",
        "\n",
        "fig,ax = plt.subplots(1, 3, figsize=(20,20))\n",
        "ax[0].imshow(inp[0])\n",
        "ax[1].imshow(gen_output[0]*255)\n",
        "ax[2].imshow(re[0])\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTKZfoaoEF22"
      },
      "source": [
        "## Build the Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ll6aNeQx8b4v",
        "colab": {}
      },
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__(name='Discriminator')\n",
        "    \n",
        "    # k3n64s1\n",
        "    self.conv1 = tf.keras.layers.Conv2D(64, 3, 1, padding='same', name='conv1')\n",
        "    self.leakyrelu1 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "    \n",
        "    #  blocks\n",
        "    # conv2_1, k3n64s2\n",
        "    self.conv21 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', name='conv21')\n",
        "    self.bn21 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu21 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "     \n",
        "    # conv2_2, k3n128s1\n",
        "    self.conv22 = tf.keras.layers.Conv2D(128, 3, 1, padding='same')\n",
        "    self.bn22 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu22 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    # conv2_3, k3n128s2\n",
        "    self.conv23 = tf.keras.layers.Conv2D(128, 3, 2, padding='same')\n",
        "    self.bn23 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu23 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    # conv2_4, k3n256s1\n",
        "    self.conv24 = tf.keras.layers.Conv2D(256, 3, 1, padding='same')\n",
        "    self.bn24 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu24 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    # conv2_5, k3n256s2\n",
        "    self.conv25 = tf.keras.layers.Conv2D(256, 3, 2, padding='same')\n",
        "    self.bn25 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu25 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    # conv2_6, k3n512s1\n",
        "    self.conv26 = tf.keras.layers.Conv2D(512, 3, 1, padding='same')\n",
        "    self.bn26 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu26 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    # conv2_7, k3n512s2 -- end of B residual block\n",
        "    self.conv27 = tf.keras.layers.Conv2D(512, 3, 2, padding='same')\n",
        "    self.bn27 = tf.keras.layers.BatchNormalization()\n",
        "    self.leakyrelu27 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense1 = tf.keras.layers.Dense(1024, name='d_den_1')\n",
        "    self.leakyrelu3 = tf.keras.layers.LeakyReLU(alpha=0.2)\n",
        "    self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid', name='d_den_2')\n",
        "    \n",
        "\n",
        "  def call(self, input_tensor, training=False):\n",
        "    input_tensor = self.conv1(input_tensor)\n",
        "    input_tensor = self.leakyrelu1(input_tensor)\n",
        "    \n",
        "    # conv2_1, k3n64s2\n",
        "    x = self.conv21(input_tensor)\n",
        "    x = self.bn21(x)\n",
        "    x = self.leakyrelu21(x)                          \n",
        "     \n",
        "    # conv2_2, k3n128s1\n",
        "    x = self.conv22(x)          \n",
        "    x = self.bn22(x)               \n",
        "    x = self.leakyrelu22(x)                        \n",
        "\n",
        "    # conv2_3, k3n128s2\n",
        "    x = self.conv23(x)         \n",
        "    x = self.bn23(x)                \n",
        "    x = self.leakyrelu23(x)                         \n",
        "\n",
        "    # conv2_4, k3n256s1\n",
        "    x = self.conv24(x)           \n",
        "    x = self.bn24(x)                \n",
        "    x = self.leakyrelu24(x)            \n",
        "\n",
        "    # conv2_5, k3n256s2\n",
        "    x = self.conv25(x)           \n",
        "    x = self.bn25(x)                \n",
        "    x = self.leakyrelu25(x)            \n",
        "\n",
        "    # conv2_6, k3n512s1\n",
        "    x = self.conv25(x)           \n",
        "    x = self.bn25(x)                \n",
        "    x = self.leakyrelu25(x)            \n",
        "\n",
        "    # conv2_7, k3n512s2 -- end of B residual block\n",
        "    x = self.conv25(x)           \n",
        "    x = self.bn25(x)                \n",
        "    x = self.leakyrelu25(x)            \n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.leakyrelu3(x)\n",
        "    x = self.dense2(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkA05NE6QMs",
        "colab": {}
      },
      "source": [
        "discriminator = Discriminator()\n",
        "disc_out = discriminator(tf.ones_like(gen_output), training=False)\n",
        "print(disc_out)\n",
        "disc_out = discriminator(tf.zeros_like(gen_output), training=False)\n",
        "print(disc_out)\n",
        "disc_out = discriminator(gen_output, training=False)\n",
        "print(disc_out)\n",
        "disc_out = discriminator(re, training=False)\n",
        "print(disc_out)\n",
        "disc_out = discriminator(tf.image.resize(inp, [IMG_HEIGHT, IMG_WIDTH]), training=False)\n",
        "print(disc_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss functions and the optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cyhxTuvJyIHV",
        "colab": {}
      },
      "source": [
        "LAMBDA = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q1Xbz5OaLj5C",
        "colab": {}
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wkMNfBWlT-PV",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "  return total_disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "90BIcCKcDMxz",
        "colab": {}
      },
      "source": [
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iWCn_PVdEJZ7",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aKUZnDiqQrAh"
      },
      "source": [
        "## Checkpoints (Object-based saving)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJnftd5sQsv6",
        "colab": {}
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NS2GWywBbAWo",
        "colab": {}
      },
      "source": [
        "EPOCHS = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input, tar):\n",
        "  # the training=True is intentional here since\n",
        "  # we want the batch statistics while running the model\n",
        "  # on the test dataset. If we use training=False, we will get\n",
        "  # the accumulated statistics learned from the training dataset\n",
        "  # (which we don't want)\n",
        "  prediction = model(test_input, training=True)\n",
        "  plt.figure(figsize=(15,15))\n",
        "\n",
        "  display_list = [test_input[0], tar[0], prediction[0]]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    # getting the pixel values between [0, 1] to plot it.\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KBKUV2sKXDbY",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train_step(input_image, target):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_image, training=True)\n",
        "    disc_real_output = discriminator(target, training=True)\n",
        "    disc_generated_output = discriminator(gen_output, training=True)\n",
        "    gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  generator_gradients = gen_tape.gradient(gen_loss,\n",
        "                                          generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2M7LmLtGEMQJ",
        "colab": {}
      },
      "source": [
        "def fit(train_ds, epochs, test_ds):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    # Train\n",
        "    for input_image, target in train_ds:\n",
        "      train_step(input_image, target)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    # Test on the same image so that the progress of the model can be \n",
        "    # easily seen.\n",
        "    for example_input, example_target in test_ds.take(1):\n",
        "      generate_images(generator, example_input, example_target)\n",
        "\n",
        "    # saving (checkpoint) the model every 20 epochs\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                        time.time()-start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a1zZmKmvOH85",
        "colab": {}
      },
      "source": [
        "fit(train_dataset, EPOCHS, test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kz80bY3aQ1VZ"
      },
      "source": [
        "## Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HSSm4kfvJiqv",
        "colab": {}
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4t4x69adQ5xb",
        "colab": {}
      },
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1RGysMU_BZhx"
      },
      "source": [
        "## Generate using test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KUgSnmy2nqSP",
        "colab": {}
      },
      "source": [
        "# Run the trained model on the entire test dataset\n",
        "for inp, tar in test_dataset.take(5):\n",
        "  generate_images(generator, inp, tar)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}