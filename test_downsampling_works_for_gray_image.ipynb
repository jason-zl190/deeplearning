{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_downsampling_works_for_gray_image.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jason-zl190/deeplearning/blob/master/test_downsampling_works_for_gray_image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQBPuiNEh4T1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "97404410-b868-4666-ccdd-dc552ee30837"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "#from bicubic_downsample import build_filter, apply_bicubic_downsample\n",
        "\n",
        "\n",
        "\n",
        "caltech_birds2010_builder = tfds.builder(\"caltech_birds2010\")\n",
        "caltech_birds2010_builder.download_and_prepare()\n",
        "caltech_birds2010_train = caltech_birds2010_builder.as_dataset(split=\"train\")\n",
        "caltech_birds2010_train\n",
        "HR_caltech_birds2010_train = caltech_birds2010_train.shuffle(1024).batch(100)\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-rQ4C5SmbU2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = caltech_birds2010_train.shuffle(400).take(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugsvkaOqcXBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "01fb3ffd-aeb9-4227-e78c-6f300643deb4"
      },
      "source": [
        "!pip install --upgrade tensorflow-probability"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-probability\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/72/29ef1e5f386b65544d4e7002dfeca1e55b099ed182cd6d405c21a19ae259/tensorflow_probability-0.8.0-py2.py3-none-any.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-probability) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast<0.3,>=0.2 in /tensorflow-2.0.0/python3.6 (from tensorflow-probability) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /tensorflow-2.0.0/python3.6 (from tensorflow-probability) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (4.4.0)\n",
            "Collecting cloudpickle==1.1.1 (from tensorflow-probability)\n",
            "  Downloading https://files.pythonhosted.org/packages/24/fb/4f92f8c0f40a0d728b4f3d5ec5ff84353e705d8ff5e3e447620ea98b06bd/cloudpickle-1.1.1-py2.py3-none-any.whl\n",
            "Installing collected packages: cloudpickle, tensorflow-probability\n",
            "  Found existing installation: cloudpickle 0.6.1\n",
            "    Uninstalling cloudpickle-0.6.1:\n",
            "      Successfully uninstalled cloudpickle-0.6.1\n",
            "  Found existing installation: tensorflow-probability 0.7.0\n",
            "    Uninstalling tensorflow-probability-0.7.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.7.0\n",
            "Successfully installed cloudpickle-1.1.1 tensorflow-probability-0.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cloudpickle"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEHQRonSbuNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_probability as tfp\n",
        "def gaussian_kernel(size: int,\n",
        "                    mean: float,\n",
        "                    std: float,\n",
        "                   ):\n",
        "    \"\"\"Makes 2D gaussian Kernel for convolution.\"\"\"\n",
        "\n",
        "    d = tfp.distributions.Normal(mean, std)\n",
        "\n",
        "    vals = d.prob(tf.range(start = -size, limit = size + 1, dtype = tf.float32))\n",
        "\n",
        "    gauss_kernel = tf.einsum('i,j->ij',\n",
        "                                  vals,\n",
        "                                  vals)\n",
        "\n",
        "    return gauss_kernel / tf.reduce_sum(gauss_kernel)\n",
        "\n",
        "# Make Gaussian Kernel with desired specs.\n",
        "gauss_kernel = gaussian_kernel(3, 0, 20 )\n",
        "\n",
        "# Expand dimensions of `gauss_kernel` for `tf.nn.conv2d` signature.\n",
        "gauss_kernel = gauss_kernel[:, :, tf.newaxis, tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVhFp2XtfjoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "eb5cf3f7-cc52-4e42-d3d9-9f631c365eac"
      },
      "source": [
        "tf.squeeze(lr[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=795, shape=(500, 500), dtype=float32, numpy=\n",
              "array([[0.2050405 , 0.27714023, 0.29497746, ..., 0.28209975, 0.2675722 ,\n",
              "        0.20006603],\n",
              "       [0.27654618, 0.3728223 , 0.39590815, ..., 0.37974483, 0.35907772,\n",
              "        0.2678666 ],\n",
              "       [0.2932054 , 0.3945168 , 0.41785625, ..., 0.40492502, 0.38146794,\n",
              "        0.28350863],\n",
              "       ...,\n",
              "       [0.3019523 , 0.40350834, 0.42671344, ..., 0.4270184 , 0.40452367,\n",
              "        0.30038384],\n",
              "       [0.28455475, 0.38042957, 0.40250745, ..., 0.4051662 , 0.38354725,\n",
              "        0.28463137],\n",
              "       [0.21105121, 0.28222266, 0.2985278 , ..., 0.30140215, 0.28517297,\n",
              "        0.21157606]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RSHvlKOmxkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "492f5e17-70df-480b-e294-53c664ae0e51"
      },
      "source": [
        "for x in a: break\n",
        "\n",
        "image = tf.expand_dims(tf.cast(x['image'], tf.float32) / 255.0, 0)\n",
        "height = image[0].shape[0]\n",
        "width = image[0].shape[1]\n",
        "image = image[0,:,:,0]\n",
        "image = tf.reshape(image, [1,height, width,1])\n",
        "hr = tf.image.resize(image, [height, height])\n",
        "\n",
        "\n",
        "lr = tf.nn.conv2d(hr, gauss_kernel, strides=[1,1,1,1], padding='SAME')\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(1, 3)\n",
        "ax[0].imshow(tf.squeeze(image[0]))\n",
        "ax[1].imshow(tf.squeeze(hr[0]))\n",
        "ax[2].imshow(tf.squeeze(lr[0]))\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-aea20af3949e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgauss_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1911\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m                 name=name)\n\u001b[0m\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: No algorithm worked! [Op:Conv2D]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2kuYkTrpTG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}